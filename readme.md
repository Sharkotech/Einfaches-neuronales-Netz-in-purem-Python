# ğŸ§  Einfaches Neuronales Netz in purem Python

Dieses Projekt demonstriert, wie man **ein einfaches neuronales Netz mit zwei Neuronen** und einer **Sigmoid-Aktivierungsfunktion** vollstÃ¤ndig von Hand implementieren kann â€“ **ohne Frameworks** wie TensorFlow oder PyTorch.  
Ziel ist es, die **Funktionsweise eines neuronalen Modells** (VorwÃ¤rtsdurchlauf, Fehlerberechnung und Backpropagation) praktisch zu verstehen.

---

## ğŸš€ Ãœberblick

Das Netz wird darauf trainiert, eine einfache Funktion zu lernen:

- Ausgabe `1`, wenn der Eingabewert `x` im Bereich **1 bis 10** liegt  
- Ausgabe `0`, sonst  

Die beiden Neuronen lernen also, diesen Bereich zu â€erkennenâ€œ.

Nach dem Training werden die Ergebnisse grafisch mit **matplotlib** dargestellt.

---

## âš™ï¸ Funktionsweise

1. **Aktivierungsfunktion:**  
   Sigmoid-Funktion  
   \[
   Ïƒ(z) = \frac{1}{1 + e^{-z}}
   \]

2. **Struktur:**  
   Zwei Neuronen (`n1` und `n2`), die gemeinsam eine einfache logische Funktion modellieren.  
   Die Ausgabe wird durch Multiplikation der beiden Neuronen berechnet:  
   \[
   y_{pred} = n1 \times n2
   \]

3. **Lernverfahren:**  
   - Quadratischer Fehler  
   - Backpropagation  
   - Stochastische Gradientenabstiegs-Methode (SGD)  
   - Sehr kleine Lernrate (`Î· = 0.000005`), um StabilitÃ¤t zu gewÃ¤hrleisten

---

## ğŸ“Š Beispielausgabe

Nach dem Training gibt das Programm Vorhersagen fÃ¼r verschiedene `x`-Werte aus und visualisiert die Ergebnisse:

![Plot der KI-Ausgabe](Ausgabenkurve.png)

*(Beispiel: Ausgabe â‰ˆ 1 im Bereich 1â€“10, sonst â‰ˆ 0)*

---

## ğŸ’» Verwendung

### Voraussetzungen
- Python 3.8 oder hÃ¶her  
- `matplotlib`

### AusfÃ¼hren
```bash
python neuronales_netz.py
